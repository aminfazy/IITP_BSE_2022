{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transer_learning_cnn_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminfazy/IITP_BSE_2022/blob/main/transer_learning_cnn_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV3jpWWaVzxL"
      },
      "source": [
        "# Transfer Learning Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go-Au1mYVzxN"
      },
      "source": [
        "## Transfer learning is a basic appoach of model reuse and retraining\n",
        "### A model trained on one dataset for a different domain is refined by modifying some of the last layers and training with new dataset\n",
        "    * This saves a lot of training time as we only need to modify some of the layers and retrain only those layers\n",
        "    * Also sometimes we don't have a very big dataset which we can use for training a model so we take pretrained model and retrain it by making only some of the layers trainable\n",
        "    * This is one of the basic techniques for domain adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZMuPsLeVzxP"
      },
      "source": [
        "### This is a basic example from keras examples directory\n",
        "(Available @ https://github.com/keras-team/keras/blob/master/examples/mnist_transfer_cnn.py) \n",
        "\n",
        "    * - Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
        "    * - Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9].\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq-x20rjVzxQ"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.utils import np_utils "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0d0Wao5VzxV"
      },
      "source": [
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128  # no.of elements to be used for one iteration\n",
        "num_classes = 5   # no. of classes for training\n",
        "epochs = 1        # how many times the whole dataset should be iterated\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = 2\n",
        "# convolution kernel size \n",
        "kernel_size = 3  # here kernel_size means a 3x3 filter\n",
        "\n",
        "if K.image_data_format() == 'channels_first':  # channels mean no. of color channels of the image\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)    # tensorflow uses channels_last config by default"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7v5c7MuVzxZ"
      },
      "source": [
        "### Define the funtion which will run the training with input model and training data \n",
        "    This function basically does some preprocessing on training data and then runs compile and fit functions of keras.models.Sequential "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlhI0XceVzxa"
      },
      "source": [
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = np_utils.to_categorical(train[1], num_classes)\n",
        "    y_test = np_utils.to_categorical(test[1], num_classes)\n",
        "\n",
        "    # compile the model\n",
        "    # you can chnage the parameters in this compile function\n",
        "    # custom funtions for loss and opitizer can be used: ref to keras documentation for more\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    t = now()\n",
        "    \n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnJPmvcmVzxd"
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# create two datasets one with digits below 5 and one with 5 and above\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtmmlBX6Vzxg"
      },
      "source": [
        "# define two groups of layers: feature (convolutions) and classification (dense)\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caNz-QGXVzxj",
        "outputId": "7631c5f4-5bf9-427f-f067-73d18bc371dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n",
        "\n",
        "# train model for 5-digit classification [0..4]\n",
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 51s 211ms/step - loss: 1.6181 - accuracy: 0.1892 - val_loss: 1.5756 - val_accuracy: 0.2477\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 52s 218ms/step - loss: 1.5689 - accuracy: 0.2723 - val_loss: 1.5212 - val_accuracy: 0.4160\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 51s 213ms/step - loss: 1.5183 - accuracy: 0.3749 - val_loss: 1.4650 - val_accuracy: 0.6602\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 50s 210ms/step - loss: 1.4659 - accuracy: 0.4733 - val_loss: 1.4041 - val_accuracy: 0.7848\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 49s 204ms/step - loss: 1.4051 - accuracy: 0.5668 - val_loss: 1.3345 - val_accuracy: 0.8449\n",
            "Training time: 0:04:22.779622\n",
            "Test score: 1.3344688415527344\n",
            "Test accuracy: 0.8449114561080933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in hdf5 format\n",
        "\n",
        "model.save(\"model_1.h5\")"
      ],
      "metadata": {
        "id": "aX1f5VblLwoh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model as a new model object\n",
        "\n",
        "from keras.saving.hdf5_format import load_model_from_hdf5\n",
        "from keras.models import load_model\n",
        "model_2 = load_model_from_hdf5(\"model_1.h5\")"
      ],
      "metadata": {
        "id": "iNq0sZ-kMJHI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the model whether it matches the previous model or not\n",
        "# Let's check the summary for comparison\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJlm__UtMpyY",
        "outputId": "4224169e-3383-4d45-9a74-cbc79fd9da19"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               589952    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600,165\n",
            "Trainable params: 600,165\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# layer_output = model.get_layer('vgg16').get_layer('block3_conv1').output\n",
        "# We need access to the layers for various manipulations \n",
        "\n",
        "layer_output = model_2.layers\n",
        "\n",
        "for idx in range(len(model_2.layers)):\n",
        "  print(model_2.get_layer(index = idx).name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hgxFg38NYJO",
        "outputId": "88ce8faa-ad12-4b28-daab-88179e7ebb29"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv2d\n",
            "activation\n",
            "conv2d_1\n",
            "activation_1\n",
            "max_pooling2d\n",
            "dropout\n",
            "flatten\n",
            "dense\n",
            "activation_2\n",
            "dropout_1\n",
            "dense_1\n",
            "activation_3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How do we check the weights of the model\n",
        "\n",
        "model_2.get_layer('conv2d').get_weights()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU9OBx_iQlHx",
        "outputId": "c5d15629-a700-4914-ffc5-e07328d120ed"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[[-0.03345221, -0.06924943,  0.01241054, -0.0279286 ,\n",
              "            0.13545208, -0.02964871, -0.04199512,  0.08152123,\n",
              "            0.07823996, -0.089711  , -0.0186399 , -0.00643799,\n",
              "            0.04886724,  0.02160867,  0.09711806,  0.0177983 ,\n",
              "           -0.04666913,  0.00059156, -0.08043575, -0.10659873,\n",
              "           -0.05022452, -0.02692206,  0.03042031, -0.04926324,\n",
              "            0.0049313 , -0.09893714,  0.02643462,  0.09612635,\n",
              "            0.11015517,  0.10334422,  0.12001359,  0.0196844 ]],\n",
              " \n",
              "         [[ 0.12482091,  0.06414187,  0.05248322,  0.00567564,\n",
              "            0.08036725,  0.12194674,  0.03858657, -0.0886545 ,\n",
              "            0.10085871, -0.10280392, -0.03848182, -0.00766634,\n",
              "            0.13827725,  0.09112118,  0.01961266,  0.04886862,\n",
              "            0.07698962,  0.01866923, -0.08646477, -0.09038078,\n",
              "           -0.0548382 , -0.09671479,  0.05233694, -0.1185357 ,\n",
              "            0.1152828 , -0.02767426, -0.0422859 , -0.00964746,\n",
              "            0.06996392,  0.13275747,  0.09779562, -0.10463466]],\n",
              " \n",
              "         [[ 0.12150536,  0.1396648 , -0.14123182,  0.00312493,\n",
              "            0.03693277, -0.09975992,  0.05368603, -0.05276572,\n",
              "           -0.04908085, -0.07904297, -0.00222653,  0.02659536,\n",
              "           -0.06382378, -0.01203593, -0.08515452,  0.09746579,\n",
              "            0.02030911,  0.07042801, -0.13833977,  0.01913231,\n",
              "           -0.04200292, -0.10229595, -0.06048825,  0.13261573,\n",
              "            0.084173  , -0.05540376, -0.02489616,  0.01573944,\n",
              "           -0.00777298,  0.10074595,  0.02716732, -0.13938276]]],\n",
              " \n",
              " \n",
              "        [[[ 0.08730949, -0.12049825, -0.09544672, -0.08551633,\n",
              "           -0.0570713 , -0.06246485, -0.03587715,  0.08530936,\n",
              "           -0.12258   , -0.13508213, -0.08044411, -0.1120519 ,\n",
              "            0.084858  , -0.01344342,  0.01332562,  0.12847635,\n",
              "           -0.13468105,  0.09848501, -0.04921355, -0.14097789,\n",
              "            0.1082529 , -0.03891347, -0.13126405, -0.07402419,\n",
              "            0.13015774, -0.0554136 ,  0.05719275,  0.10288683,\n",
              "            0.0076721 , -0.11728552, -0.05176508,  0.13203557]],\n",
              " \n",
              "         [[ 0.00446383,  0.04659244, -0.13994546, -0.10415946,\n",
              "            0.07535747, -0.01760151, -0.12017737,  0.03387521,\n",
              "            0.09566654,  0.08387318, -0.09774946, -0.04451987,\n",
              "            0.04234133, -0.03539335, -0.09421714,  0.03796183,\n",
              "           -0.07437784, -0.06024368,  0.128     , -0.08506739,\n",
              "           -0.05408108,  0.00485334, -0.01288858, -0.06117951,\n",
              "           -0.1042589 ,  0.11692099,  0.01234716,  0.00179373,\n",
              "           -0.09339257,  0.02210383,  0.12045214, -0.00155662]],\n",
              " \n",
              "         [[-0.08980199,  0.09871726, -0.07411375, -0.09866569,\n",
              "            0.08438569, -0.05523087, -0.02937719, -0.10917164,\n",
              "            0.03850899, -0.02316329, -0.03277201,  0.13626929,\n",
              "           -0.08056545, -0.05811884,  0.07987495,  0.14108814,\n",
              "           -0.1124486 , -0.05219254, -0.10859612, -0.09808204,\n",
              "           -0.1244697 ,  0.08415474, -0.04889483,  0.09980775,\n",
              "           -0.04142436,  0.11226269,  0.07758074, -0.08560736,\n",
              "            0.01259856,  0.03153516,  0.08744051, -0.14170986]]],\n",
              " \n",
              " \n",
              "        [[[ 0.07624952,  0.09328511, -0.02740732, -0.0045465 ,\n",
              "           -0.06720187,  0.03365072, -0.09873631,  0.09367397,\n",
              "           -0.00251253,  0.02875547, -0.13199185,  0.0980612 ,\n",
              "            0.07707315, -0.11973751, -0.00333907,  0.13893038,\n",
              "           -0.06509986,  0.09526353, -0.08380777, -0.08103936,\n",
              "           -0.11448628,  0.07016436, -0.10078208,  0.11030456,\n",
              "           -0.00084397, -0.03740137,  0.06953786, -0.00762158,\n",
              "           -0.01753333,  0.13285041, -0.01847539, -0.01519213]],\n",
              " \n",
              "         [[ 0.03575886, -0.01061331, -0.12000111,  0.13970655,\n",
              "           -0.05240293,  0.08258703, -0.00538411,  0.09906546,\n",
              "           -0.04897797,  0.05192863, -0.00571553,  0.11203612,\n",
              "            0.1224888 , -0.03801214, -0.04504917, -0.06222232,\n",
              "           -0.0143429 ,  0.0143048 ,  0.0397178 , -0.13421908,\n",
              "            0.00819529,  0.01600318, -0.07544799, -0.02033056,\n",
              "            0.08724203,  0.0857446 ,  0.08377052, -0.10480617,\n",
              "           -0.12534542, -0.07893378,  0.05189689, -0.09625923]],\n",
              " \n",
              "         [[-0.11811625,  0.06490095,  0.12156306,  0.04821613,\n",
              "           -0.04038221,  0.07742944, -0.12458959, -0.09824463,\n",
              "            0.03864611,  0.08331805, -0.08808374, -0.04243428,\n",
              "            0.01195973,  0.10031531, -0.0152769 ,  0.11296293,\n",
              "           -0.12238102, -0.09088529, -0.08643752, -0.1084254 ,\n",
              "           -0.01359532, -0.05419179, -0.1233839 ,  0.13589574,\n",
              "            0.10790054,  0.11390092, -0.01670575, -0.1307763 ,\n",
              "            0.00764738,  0.10589784,  0.1080371 , -0.03853136]]]],\n",
              "       dtype=float32),\n",
              " array([ 6.6895450e-06, -8.4129686e-05, -3.7034940e-07,  1.7038474e-03,\n",
              "        -3.0772417e-04, -2.8343147e-04, -2.8283868e-04,  8.2579063e-04,\n",
              "        -8.2131411e-04,  2.0975844e-04,  0.0000000e+00,  4.8489991e-04,\n",
              "         2.7634885e-06, -1.4079741e-03,  7.7276694e-04,  2.4680016e-04,\n",
              "         3.4835364e-04,  2.2920170e-04,  2.0067261e-03, -3.0015735e-05,\n",
              "        -1.8118686e-04,  5.3052863e-06,  1.0986798e-04,  5.5349147e-04,\n",
              "         4.7553431e-06, -4.2364582e-06,  2.9029394e-04,  2.6880993e-04,\n",
              "        -9.1599592e-04, -3.8261432e-04,  2.9425879e-04, -5.4559868e-04],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether a layer in the model is traiable or not\n",
        "\n",
        "model_2.get_layer('conv2d').trainable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0KexNN2Q8kS",
        "outputId": "85a4e64a-8d52-407e-f10f-0f01c911e960"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the layer attribute to make is trainable or non-trainable\n",
        "\n",
        "model_2.get_layer('conv2d').traninable = False\n",
        "\n",
        "model_2.get_layer('conv2d').traninable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3AnFCC9RHFF",
        "outputId": "f6a913ec-7091-48a3-927a-174e8bfad239"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWRUTPmiVzxn"
      },
      "source": [
        "### Model trained in the above block can be used for classifying digits 5 to 9 by fine tuning it\n",
        "    For fine tuning we will freeze all the convolutional and maxpooling layers (feature layers)\n",
        "    This can be done by making those layers non-trainable\n",
        "    only the top(last) two layers (dense layers) are left trainable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transfer: train dense layers for new classification task [5..9]\n",
        "train_model(model_2,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5w-rWKiSlsD",
        "outputId": "e3d1f2f2-239f-49ab-e93b-d440b8569ac4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 47s 203ms/step - loss: 1.6115 - accuracy: 0.2364 - val_loss: 1.5716 - val_accuracy: 0.3125\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 47s 204ms/step - loss: 1.5688 - accuracy: 0.2797 - val_loss: 1.5258 - val_accuracy: 0.3800\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 47s 205ms/step - loss: 1.5264 - accuracy: 0.3364 - val_loss: 1.4789 - val_accuracy: 0.4678\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 46s 201ms/step - loss: 1.4801 - accuracy: 0.4070 - val_loss: 1.4292 - val_accuracy: 0.5746\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 48s 207ms/step - loss: 1.4323 - accuracy: 0.4731 - val_loss: 1.3749 - val_accuracy: 0.6733\n",
            "Training time: 0:04:22.588144\n",
            "Test score: 1.3748985528945923\n",
            "Test accuracy: 0.6733182668685913\n"
          ]
        }
      ]
    }
  ]
}