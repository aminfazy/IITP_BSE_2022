{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_conv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminfazy/FPD_IITP_21/blob/main/CONV_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kjTsII0qfuL"
      },
      "source": [
        "# Import necessary Packages\n",
        " \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.utils\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8IIJncGiQ2M"
      },
      "source": [
        "# Get the dataset\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data() \t#Keras function\n",
        "\n",
        "print (\"mnist data downloaded...\")\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CwHiVn9sonK"
      },
      "source": [
        "# This code cell is for visualization of data only...may be skipped\n",
        "\n",
        "# plot images...subplot function is being used...nice documentation is available on the official webpage of matplotlib\n",
        "# arguments to subplot functions are number of rows, number of columns and \n",
        "# number of subplots in the plot...comma is mandatory if values are less than 10\n",
        "\n",
        "plt.subplot(221)\t\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray')) # ploting first image of training data set\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[134], cmap=plt.get_cmap('gray'))\t# ploting 135th image in training data set\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_test[244], cmap=plt.get_cmap('gray'))\t# ploting 244rth image of test date set\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_test[3], cmap=plt.get_cmap('gray'))\t# ploting 4th image of test data set\n",
        "\n",
        "# show the plot\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PetdwiQsDjq"
      },
      "source": [
        "# Print shape of dataset..it will print three tuples, namely the no. of images in dataset, height and width(60000, 28, 28)\n",
        "\n",
        "print (X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yMtIFlycEVH"
      },
      "source": [
        "print (Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xwxGQy2sFIc"
      },
      "source": [
        "# Do basic preprocessing of the training data\n",
        "\n",
        "# reshaping the data \n",
        "X_train = X_train.reshape(60000,28,28)\n",
        "X_test = X_test.reshape(10000,28,28)\n",
        "\n",
        "for_final_test = X_test # we will use this for running predictions\n",
        "\n",
        "# Change the data type from int to float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize the images\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print(X_train.shape[0], 'training samples')\n",
        "print(X_test.shape[0], 'test samples')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJITEAxsjwWp"
      },
      "source": [
        "# Convert the class labels to one hot encoded matrix\n",
        "from keras.utils import np_utils\n",
        "\n",
        "num_classes = 10 # number of classess for classification \n",
        "\n",
        "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = np_utils.to_categorical(Y_test, num_classes)\n",
        "\n",
        "print(Y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtPgp5lStzjk"
      },
      "source": [
        "# Define model architecture\n",
        "\n",
        "rows, cols = 28,28\n",
        "input_shape = (rows, cols, 1)\n",
        "model = Sequential()\n",
        "\n",
        "#arch 1\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten()) #Flattens the input, Why ? because we need to connect it to Dense layer\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# another architecture...you may experiment with the following architecture\n",
        "#arch 2\n",
        "#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model.add(Dropout(0.25))\n",
        "#model.add(Flatten()) # Flattens the input\n",
        "#model.add(Dense(128, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "#model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "print (\"keep going...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl0RQYZyuHE1"
      },
      "source": [
        "# compiling model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
        "\n",
        "print (\"compile successful...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npPQMD752vA9"
      },
      "source": [
        "# print model summary\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRCZOEUmuKCD"
      },
      "source": [
        "# Now we train the model\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "\n",
        "# start the training\n",
        "\n",
        "history=model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n",
        "\n",
        "print (\"training done...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEmU2ZbBuT5M"
      },
      "source": [
        "# Evaluate the model\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=1)\n",
        "print('loss:', score[0])\n",
        "print('accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYlwMsBkoQRm"
      },
      "source": [
        "# sample = for_final_test[0,:,:]\n",
        "# sample = sample.reshape(1,28,28)\n",
        "# sample.shape\n",
        "# print(Y_test[0])\n",
        "# model.predict_classes(sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predict_x=model.predict(X_test) \n",
        "classes_x=np.argmax(predict_x,axis=1)\n",
        "print(classes_x)"
      ],
      "metadata": {
        "id": "-wRtndVI4fMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrs155-xiIDI"
      },
      "source": [
        "#printing metrices\n",
        "print (model.metrics_names)\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdB0OsTOeDga"
      },
      "source": [
        "# to visualize the performance with plots...plot loss and accuracy in training and validation \n",
        "\n",
        "# Plot for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='center right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmw7_XWZn6mC"
      },
      "source": [
        "# summarize history for loss\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}